# 📚 Paper Summarizer - 学术论文自动总结系统

一个基于 AI 的自动化工具，用于从 Google 学术邮件推送中提取、翻译和评审相关论文，并生成结构化的日报报告。

## ✨ 功能特性

- 📧 **自动邮件获取**：从 QQ 邮箱自动获取 Google 学术推送邮件，支持自定义日期范围
- 🔍 **智能筛选**：使用 AI Agent 进行相关性分析，自动筛选相关论文（遥操作、机器人动力学、力控、灵巧手等领域）
- 🌐 **智能摘要提取**：从论文原网址自动提取完整摘要，支持 PDF 和网页两种格式，使用专门的 AI Agent 精准识别摘要内容
- ✅ **摘要验证**：使用 AI Agent 验证提取的摘要是否为真实内容，防止 AI 模型虚构生成
- 🧹 **摘要清洗**：自动去除引用标记、图表引用和无意义的格式字符，使摘要更简洁易读
- 🤖 **AI 翻译**：使用 CrewAI 框架和本地 LLM（Ollama）进行专业论文翻译
- 📊 **专业评审**：自动生成结构化评审报告，包含多维度评分（创新性、技术深度、相关性、实用性）
- 📝 **日报生成**：自动生成 Markdown 格式的学术论文日报
- ⭐ **价值评估**：自动识别高价值论文（评分>3.0）
- 📊 **CSV 导出**：所有相关论文自动导出为 CSV 表格，包含翻译后的摘要，方便查看和管理
- 💾 **备份支持**：支持将报告自动备份到指定目录
- 🐛 **调试模式**：支持开启调试模式，详细记录处理过程和 Agent 输出日志
- 💻 **本地处理模式**：支持从本地 CSV 文件读取论文信息进行处理，避免重复处理相同邮件
- 🌐 **Web 界面**：提供现代化的 Web 界面，实时显示处理进度、论文状态和 Agent 工作状态
- 📡 **实时通信**：基于 WebSocket 的实时通信，支持实时日志推送和状态更新
- 🎨 **可视化展示**：三面板布局（来源、对话、生成），直观展示论文处理流程和结果
- ✏️ **摘要确认编辑**：支持在 Web 界面中手动确认和编辑提取的摘要，确保摘要质量
- 🔗 **快速访问**：点击论文框即可在新窗口打开论文原网址，方便快速查看论文详情

## 🛠️ 技术栈

- **Python 3.x**
- **CrewAI** - AI Agent 框架，用于论文翻译、评审和摘要处理
- **Ollama** - 本地大语言模型（支持 qwen2.5:32b 等模型）
- **Crawl4AI** - 网页内容抓取库，用于从论文网址获取完整内容
- **PyMuPDF** - PDF 文档处理库，用于提取 PDF 论文文本
- **IMAP** - 邮件协议
- **BeautifulSoup** - HTML 解析
- **YAML** - 配置文件
- **Pandas** - 数据处理
- **Flask** - Web 服务器框架
- **Socket.IO** - WebSocket 实时通信库

## 📋 前置要求

1. **Python 3.8+**
2. **Ollama** 已安装并运行（默认地址：`http://localhost:11434`）
3. **已下载所需模型**（如 `qwen2.5:32b`）
4. **QQ 邮箱账号**（需要开启 IMAP 服务）

## 🚀 安装步骤

### 1. 克隆仓库

```bash
git clone <your-repo-url>
cd <your-repo-name>
```

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

如果没有 `requirements.txt`，请安装以下依赖：

```bash
pip install crewai python-dotenv pyyaml beautifulsoup4 ollama pandas requests PyMuPDF crawl4ai flask flask-socketio
```

### 3. 配置环境变量

创建 `.env` 文件（不要提交到 Git）：

```env
# 邮箱配置
QMAIL_USER=your_qq_email@qq.com
QMAIL_PASSWORD=your_imap_password

# Ollama 配置
OLLAMA_MODEL=qwen2.5:32b
OLLAMA_BASE_URL=http://localhost:11434

# 其他配置
MAX_EMAILS=30

# 日期范围配置（可选）
# START_DAYS: 开始日期（前START_DAYS天，例如START_DAYS=3表示从前3天开始）
# END_DAYS: 结束日期（前END_DAYS天，例如END_DAYS=0表示到今天，END_DAYS=1表示到昨天）
START_DAYS=1
END_DAYS=0

# 备份目录配置（可选）
# 如果设置了此路径，报告会同时保存到该路径
BACKUP_DIR=

# 调试模式配置（可选）
# DEBUG_MODE=1: 开启调试模式，记录详细的处理日志
# DEBUG_MODE=0: 关闭调试模式（默认）
DEBUG_MODE=0

# 本地处理模式配置（可选）
# LOCAL=1: 开启本地处理模式，从CSV文件读取论文信息（不读取邮件）
# LOCAL=0: 关闭本地处理模式，从邮件读取论文信息（默认）
LOCAL=0

# 本地模式CSV配置（仅在LOCAL=1时有效）
CSV_FILE_PATH=papers.csv          # CSV文件路径
CSV_TITLE_COLUMN=0                # 论文标题列索引（从0开始，默认第1列）
CSV_ABSTRACT_COLUMN=2             # 摘要列索引（从0开始，默认第3列）
CSV_LINK_COLUMN=                  # 论文链接列索引（可选，从0开始，如果为空则不读取链接）
```

**注意**：QQ 邮箱需要使用授权码作为密码，不是登录密码。获取方式：
1. 登录 QQ 邮箱网页版
2. 设置 → 账户 → 开启 IMAP/SMTP 服务
3. 生成授权码

### 4. 配置关键词（可选）

编辑 `keywords.yaml` 文件，根据你的研究领域调整关键词。**注意**：v0.2 版本已改用 AI Agent 进行相关性分析，不再使用关键词匹配机制。关键词配置文件保留用于其他可能的用途。

文件包含三类关键词：

- **high_priority**：高优先级关键词
- **related**：相关关键词
- **exclude**：排除关键词（暂未使用）

## 📖 使用方法

### 方式一：Web 界面（推荐）

启动 Web 服务器：

```bash
python web_server.py
```

服务器启动后会自动打开浏览器访问 `http://localhost:5000`。Web 界面提供：

- **左侧面板（来源）**：配置运行模式（本地模式/远程模式）、选择 CSV 文件或设置日期范围，查看论文列表和处理状态
- **中间面板（对话）**：实时显示处理日志、Agent 工作状态和系统消息
- **右侧面板（生成）**：显示生成的文件列表，点击可直接打开文件

Web 界面支持：
- 实时查看论文处理进度和状态
- 查看每篇论文的摘要（点击论文可展开）
- 点击论文框跳转到论文原网址（在新窗口打开）
- 实时查看 Agent 工作状态和输出
- 一键打开生成的文件
- 人工确认和编辑摘要（v0.4 新增）：在摘要提取完成后，可以在界面中查看、编辑和确认摘要，确保摘要质量后再继续处理

### 方式二：命令行模式

```bash
python run_summarizer.py
```

程序将：
1. 根据模式选择数据源：
   - **邮件模式**（默认）：连接 QQ 邮箱，根据配置的日期范围获取 Google 学术推送邮件（默认：前1天到今天）
   - **本地模式**（LOCAL=1）：从指定的 CSV 文件读取论文信息
2. 提取论文信息并使用相关性分析 AI Agent 筛选相关论文
3. 从论文原网址获取完整摘要（支持 PDF 和网页两种格式）
4. 使用 AI Agent 验证、清洗摘要内容
5. 使用 CrewAI 框架和 AI 进行专业翻译和评审
6. 生成日报报告并保存到 `reports/` 目录
7. 将所有相关论文导出到 CSV 文件（包含翻译后的摘要）

### 输出文件

生成的报告保存在 `reports/` 目录下，文件名格式：
```
Robotics_Academic_Daily_YYYYMMDD.md
```

报告包含：
- 🔥 **高价值论文**（评分>3.0，建议深入研究）
  - 包含完整的评审内容（核心贡献、技术方法、相关性分析、技术价值、值得关注的原因）
  - 包含详细的评分信息（JSON 格式）
  - 包含翻译后的摘要
- 📖 **相关论文**（其他相关论文）
  - 包含评审内容和评分信息
  - 包含翻译后的摘要（如果提取成功）
- 📊 **统计信息**（论文数量统计）

同时会生成 CSV 文件：
```
相关论文_YYYYMMDD.csv              # 所有相关论文列表（包含标题、链接、翻译后的摘要和处理结果）
```

CSV 文件说明：
- **相关论文 CSV**：包含论文标题、链接、翻译后的摘要（如果提取和翻译成功）和处理结果（1=成功，0=失败），方便查看和管理

## 📁 项目结构

```
.
├── README.md                    # 项目说明文档
├── run_summarizer.py            # 主程序文件
├── web_server.py                # Web 服务器（Flask + Socket.IO）
├── web_interface.html           # Web 界面前端
├── keywords.yaml                # 关键词配置文件
├── requirements.txt             # Python 依赖列表
├── .env                         # 环境变量配置（不提交到 Git）
├── reports/                     # 生成的报告目录
│   ├── Robotics_Academic_Daily_*.md  # 日报文件（Markdown 格式）
│   └── 相关论文_*.csv          # 相关论文 CSV 文件
├── crewai_logs/                 # CrewAI Agent 处理日志目录（调试模式）
├── debug/                       # 系统调试日志目录（调试模式）
└── downloads/                   # PDF 文件下载目录（自动保存从网址下载的 PDF）
```

## ⚙️ 配置说明

### 环境变量

| 变量名 | 说明 | 默认值 |
|--------|------|--------|
| `QMAIL_USER` | QQ 邮箱账号 | 必填 |
| `QMAIL_PASSWORD` | QQ 邮箱 IMAP 授权码 | 必填 |
| `OLLAMA_MODEL` | Ollama 模型名称 | `qwen2.5:32b` |
| `OLLAMA_BASE_URL` | Ollama 服务地址 | `http://localhost:11434` |
| `MAX_EMAILS` | 最大处理邮件数 | `30` |
| `START_DAYS` | 开始日期（前START_DAYS天） | `1` |
| `END_DAYS` | 结束日期（前END_DAYS天，0表示今天） | `0` |
| `BACKUP_DIR` | 备份目录路径（可选） | 空（不备份） |
| `DEBUG_MODE` | 调试模式（1=开启，0=关闭） | `0` |
| `LOCAL` | 本地处理模式（1=开启，0=关闭） | `0` |
| `CSV_FILE_PATH` | 本地模式CSV文件路径 | `papers.csv` |
| `CSV_TITLE_COLUMN` | 论文标题列索引（从0开始） | `0` |
| `CSV_ABSTRACT_COLUMN` | 摘要列索引（从0开始） | `2` |
| `CSV_LINK_COLUMN` | 论文链接列索引（可选，从0开始） | 空 |

### 相关性分析机制

v0.2 版本使用 AI Agent 进行相关性分析，替代了之前的关键词匹配机制。相关性分析 Agent 会基于论文标题和邮件片段信息，智能判断论文是否符合以下研究方向：

- 遥操作（Teleoperation）
- 力控（Force Control）
- 灵巧手（Dexterous Manipulation/Hand）
- 机器人动力学（Robot Dynamics）
- 机器学习（Machine Learning，仅当应用于机器人控制领域时）

AI Agent 会严格基于提供的信息进行分析，不会虚构或推测论文内容，确保判断的准确性和可靠性。

## 🔧 自定义配置

### 修改日期范围

通过环境变量配置：
```env
START_DAYS=3  # 从前3天开始
END_DAYS=0    # 到今天结束
```

或在代码中直接修改：
```python
START_DAYS = 1  # 从前1天开始
END_DAYS = 0    # 到今天结束
```

### 修改邮件搜索条件

在 `run_summarizer.py` 的 `fetch_scholar_emails` 函数中修改搜索条件：

```python
search_criteria = f'(FROM "scholaralerts-noreply@google.com" SINCE {start_date_str} BEFORE {end_date_str})'
```

### 修改评分阈值

在 `run_summarizer.py` 的 `process_paper_with_crewai` 函数中修改：

```python
'is_high_value': score_data.get('总分', 0.0) > 3.0  # 修改阈值
```

### 修改评审维度

在 `create_review_task` 函数中修改评审维度和格式。当前评审维度包括：
- 创新性（0.0-1.0）
- 技术深度（0.0-1.0）
- 相关性（0.0-1.0）
- 实用性（0.0-1.0）
- 总分（0.0-4.0，各维度之和）

### 本地处理模式

开启本地处理模式后，程序将从 CSV 文件读取论文信息，而不是从邮件读取。适用于：
- 重复处理相同的论文列表
- 批量处理本地保存的论文信息
- 测试和调试

配置方式：
```env
LOCAL=1
CSV_FILE_PATH=papers.csv
CSV_TITLE_COLUMN=0
CSV_ABSTRACT_COLUMN=2
CSV_LINK_COLUMN=1  # 可选
```

### 调试模式

开启调试模式后，程序会详细记录处理过程：
- `crewai_logs/`：CrewAI Agent 的处理日志
- `debug/`：系统调试日志，包含论文信息、摘要提取过程等

配置方式：
```env
DEBUG_MODE=1
```

### 配置备份目录

在 `.env` 文件中设置：
```env
BACKUP_DIR=/path/to/backup/directory
```

报告将同时保存到 `reports/` 目录和备份目录。

## ⚠️ 注意事项

1. **隐私安全**：
   - 不要将 `.env` 文件提交到 Git
   - 邮箱授权码请妥善保管
   - 备份目录中的报告也包含敏感信息，请注意保护

2. **Ollama 模型**：
   - 确保 Ollama 服务正在运行
   - 确保已下载所需的模型（如 `qwen2.5:32b`）
   - 模型大小较大（32B 模型约 20GB+），请确保有足够的磁盘空间和内存
   - 建议使用性能较好的 GPU 以加快处理速度

3. **网络连接**：
   - 需要稳定的网络连接访问邮箱服务器
   - 首次运行可能需要较长时间下载模型

4. **处理时间**：
   - 每篇论文的处理时间取决于模型性能和论文长度
   - 使用 CrewAI 框架，每篇论文需要经过摘要提取、验证、清洗、翻译和评审多个步骤
   - 建议在非高峰时段运行，避免影响其他工作
   - 处理大量论文时可能需要较长时间（每篇约 2-5 分钟）

5. **CrewAI 配置**：
   - 程序已禁用 CrewAI 遥测功能
   - 确保 CrewAI 版本 >= 0.1.0
   - 如果遇到连接问题，检查 `OLLAMA_BASE_URL` 配置是否正确

6. **摘要提取**：
   - 程序会自动从论文原网址获取完整摘要
   - 支持 PDF 和网页两种格式
   - 如果摘要提取失败，该论文将跳过后续处理
   - 下载的 PDF 文件会自动保存到 `downloads/` 目录

7. **CSV 导出**：
   - CSV 文件使用 UTF-8-BOM 编码，可在 Excel 中正确显示中文
   - CSV 中包含翻译后的摘要（如果翻译成功），方便直接查看
   - 如果导出失败，检查是否有写入权限

8. **本地处理模式**：
   - CSV 文件需要包含至少标题和摘要两列
   - 如果 CSV 中没有链接列，程序会跳过摘要提取步骤，直接使用 CSV 中的摘要
   - 建议 CSV 文件使用 UTF-8 编码

9. **相关性分析**：
   - v0.2 版本使用 AI Agent 进行相关性分析，不再依赖关键词匹配
   - Agent 会基于论文标题和邮件片段信息进行智能判断
   - 如果 Agent 判断论文不符合研究方向，该论文将被跳过，不会进行后续处理

10. **摘要确认功能**（v0.4 新增）：
    - 在摘要提取完成后，程序会暂停并等待用户在 Web 界面中确认摘要
    - 用户可以在界面中查看、编辑每篇论文的摘要内容
    - 确认后的摘要将用于后续的翻译和评审流程
    - 如果确认后的摘要为空，该论文将被跳过后续处理
    - 此功能仅在 Web 界面模式下可用，命令行模式下不会暂停等待确认

## 🤝 贡献

欢迎提交 Issue 和 Pull Request！

## 📄 许可证

本项目采用 MIT 许可证。

## 🙏 致谢

- [CrewAI](https://github.com/joaomdmoura/crewAI) - AI Agent 框架
- [Ollama](https://ollama.ai/) - 本地大语言模型
- [Google Scholar](https://scholar.google.com/) - 学术论文推送服务

---

**提示**：如果遇到问题，请检查：
1. Ollama 服务是否正常运行
2. 邮箱 IMAP 服务是否已开启（邮件模式）
3. 环境变量是否正确配置
4. Python 依赖是否完整安装（包括 Flask 和 Flask-SocketIO）
5. 网络连接是否正常（需要访问论文网址）
6. Web 服务器端口 5000 是否被占用（可通过修改 `web_server.py` 中的端口号解决）
7. 如果开启调试模式，检查日志文件以获取详细错误信息

---

## 📝 版本更新日志

### v0.4 (当前版本)

#### 核心功能新增
- ✅ **人工确认摘要功能**：新增摘要人工确认和编辑功能，提高摘要质量
  - 在摘要提取完成后，程序会暂停并等待用户在 Web 界面中确认和编辑摘要
  - 用户可以在 Web 界面中查看、编辑每篇论文的摘要内容
  - 支持批量确认，确认后程序继续执行翻译和评审流程
  - 如果确认后的摘要为空，该论文将被跳过后续处理
  - 适用于需要人工审核和修正摘要的场景，确保摘要准确性

#### 技术改进
- ✅ **资源清理优化**：添加 LiteLLM 异步客户端清理机制
  - 程序退出时自动清理 LiteLLM 异步客户端，避免资源泄漏
  - 修复程序退出时的异步客户端警告问题
  - 改进事件循环管理，确保异步资源正确释放
- ✅ **日志管理优化**：配置 LiteLLM 相关日志记录器
  - 统一管理 CrewAI 和 LiteLLM 的日志输出
  - 改进日志记录格式和级别控制

#### 接口扩展
- ✅ 扩展 `main` 函数回调接口，新增 `on_waiting_confirmation` 和 `get_confirmed_abstracts` 回调
- ✅ 新增 `/api/confirm_abstracts` API 端点，用于提交确认后的摘要
- ✅ Web 界面新增摘要编辑和确认功能，支持实时编辑和批量确认

### v0.3

#### 核心功能新增
- ✅ **Web 界面**：新增现代化的 Web 界面，提供更好的用户体验
  - 三面板布局：来源面板（配置和论文列表）、对话面板（实时日志）、生成面板（文件列表）
  - 实时状态更新：基于 WebSocket 的实时通信，实时显示处理进度和状态
  - 论文状态可视化：直观显示每篇论文的处理状态（处理中、成功、失败）
  - Agent 状态展示：实时显示各个 AI Agent 的工作状态和输出信息
  - 文件管理：生成的文件可直接在界面中点击打开
- ✅ **Web 服务器**：基于 Flask 和 Socket.IO 的 Web 服务器
  - 支持本地模式和远程模式的配置切换
  - 实时日志推送和状态更新
  - 文件打开功能（自动使用系统默认程序打开文件）

#### 技术改进
- ✅ 重构 `main` 函数，支持回调函数机制，便于与 Web 服务器集成
- ✅ 新增 Agent 状态回调，实时推送 Agent 工作状态到前端
- ✅ 优化日志输出，支持分级日志（info、success、error、warning）

### v0.2

#### 核心功能改进
- ✅ **相关性分析机制升级**：取消基于关键词的匹配机制，改用 AI Agent 进行智能相关性分析
  - 新增相关性分析专家 Agent，基于论文标题和邮件片段信息进行专业判断
  - 支持五个研究方向：遥操作、力控、灵巧手、机器人动力学、机器学习（应用于机器人控制）
  - Agent 严格基于提供信息进行分析，不虚构或推测内容，确保判断准确性
- ✅ **Prompt 优化**：全面优化所有 AI Agent 的 prompt，使其更加专业和精确
  - 优化相关性分析 Agent 的 prompt，明确研究方向定义和判断标准
  - 优化摘要提取 Agent 的 prompt，强调严格禁止生成内容，只能提取现有内容
  - 优化翻译和评审 Agent 的 prompt，提高专业性和准确性

#### 功能调整
- ✅ **CSV 导出优化**：
  - 取消高价值论文单独 CSV 导出功能
  - 相关论文 CSV 现在包含翻译后的摘要，方便直接查看
  - 优化 CSV 导出逻辑，优先保存翻译后的摘要（如果翻译成功）

#### 技术改进
- ✅ 改进相关性分析流程，使用 CrewAI 框架进行智能判断
- ✅ 优化 Agent 输出解析，提高相关性判断的准确性

### v0.1

#### 修复
- ✅ 修复总评分异常问题，确保评分计算准确

#### 功能优化
- ✅ **评分维度调整**：去除"研究质量"评分维度（根据摘要无法准确判断），改为 4 个维度评分（创新性、技术深度、相关性、实用性），总分 4.0 分
- ✅ **智能摘要提取**：
  - 发现邮件中的摘要并非完整内容，改为从论文原网址获取完整摘要
  - 集成 `crawl4ai` 库用于网页内容抓取
  - 集成 `PyMuPDF` 库用于 PDF 文档处理
  - 新增 PDF 处理 Agent 和网页摘要提取 Agent，专门用于精准识别摘要信息
  - 严格规定提取成功标准，防止 AI 模型生成虚假内容
- ✅ **摘要验证机制**：新增摘要验证专家 Agent，用于判断提取的摘要是否为 AI 虚构生成，确保内容真实性
- ✅ **摘要清洗功能**：新增摘要清洗专家 Agent，自动去除引用标记（如 [1]、[2-5]）、图表引用（如图1、Table 2）和无意义的格式字符，使摘要更简洁易读
- ✅ **调试模式**：新增调试模式支持（`DEBUG_MODE=1`），开启后详细记录处理过程：
  - `crewai_logs/`：CrewAI Agent 处理日志
  - `debug/`：系统调试日志，包含论文信息、摘要提取过程等
- ✅ **本地处理模式**：新增本地处理模式（`LOCAL=1`），支持从本地 CSV 文件读取论文信息进行处理：
  - 避免重复处理相同的邮件
  - 支持自定义 CSV 列索引（标题列、摘要列、链接列）
  - 适用于批量处理和测试场景
- ✅ **输出格式优化**：
  - 将输出表格格式从 Excel（xlsx）改为 CSV
  - 新增"相关论文"CSV 导出，记录所有符合关键词的论文及其处理结果
  - CSV 文件包含摘要提取状态标识（1=成功，0=失败）
  - 如果摘要提取成功，CSV 中会保存完整摘要
- ✅ **统计信息优化**：删除统计信息中的"高价值论文平均评分"（无实际意义）

#### 技术改进
- ✅ 优化摘要提取流程，支持 PDF 和网页两种格式的自动识别和处理
- ✅ 改进错误处理机制，摘要提取失败的论文会跳过后续处理，但会记录到 CSV 中
- ✅ 优化 Agent 输出解析，提高提取结果的准确性


