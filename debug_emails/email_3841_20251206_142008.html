<!doctype html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:o="urn:schemas-microsoft-com:office:office"><head><!--[if gte mso 9]><xml><o:OfficeDocumentSettings><o:AllowPNG/><o:PixelsPerInch>96</o:PixelsPerInch></o:OfficeDocumentSettings></xml><![endif]--><style>body{background-color:#fff}.gse_alrt_title{text-decoration:none}.gse_alrt_title:hover{text-decoration:underline} @media screen and (max-width: 599px) {.gse_alrt_sni br{display:none;}}</style></head><body><!--[if gte mso 9]><table cellpadding="0" cellspacing="0" border="0"><tr><td style="width:600px"><![endif]--><div style="font-family:arial,sans-serif;font-size:13px;line-height:16px;color:#222;width:100%;max-width:600px"><h3 style="font-weight:lighter;font-size:18px;line-height:20px;"></h3><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[HTML]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://www.mdpi.com/2076-0825/14/12/587&amp;hl=zh-CN&amp;sa=X&amp;d=2225530618408107386&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjJ1_E0-WWN3wEwLTbWLpT4f&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=0&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">A Review of <font color=#DD4B39>Robot</font>-Assisted Needle-Insertion Approaches in Corneal Surgeries</a></h3><div style="color:#006621;line-height:18px">ER Zhang, AC Ramos, G Beschi, G Rocha, A Hooshiar - Actuators, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… an early overview of <font color=#DD4B39>robotic</font>-assisted ophthalmic surgery, charting the progress <br>
from general-purpose systems like the da Vinci <font color=#DD4B39>robot</font> to the development of <br>
specialized ophthalmic platforms [2]. While this review was important in defining the …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=en34Wk6s4h4J&amp;citsig=AKwmTV4AAAAAaxLpXxCPTPaMJDSXO9uzte6LYiI" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://www.mdpi.com/2076-0825/14/12/587&amp;rt=A+Review+of+Robot-Assisted+Needle-Insertion+Approaches+in+Corneal+Surgeries&amp;scisig=ABGrvjLK-b2yuKEnmEIcr6S0jllg" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://www.mdpi.com/2076-0825/14/12/587&amp;rt=A+Review+of+Robot-Assisted+Needle-Insertion+Approaches+in+Corneal+Surgeries&amp;scisig=ABGrvjLK-b2yuKEnmEIcr6S0jllg" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://www.mdpi.com/2076-0825/14/12/587&amp;rt=A+Review+of+Robot-Assisted+Needle-Insertion+Approaches+in+Corneal+Surgeries&amp;scisig=ABGrvjLK-b2yuKEnmEIcr6S0jllg" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[PDF]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://previous.scientia.report/index.php/archive/article/download/3044/3076&amp;hl=zh-CN&amp;sa=X&amp;d=14957897197829466244&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjKYIZLZWEZoCKAcnqrkEmyN&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=1&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Enhancing operational effectiveness through command and control integration of autonomous <font color=#DD4B39>robot </font>swarms</a></h3><div style="color:#006621;line-height:18px">S Babayev, R Akhundov, E Hashimov - Collection of scientific papers «SCIENTIA», 2025</div><div class="gse_alrt_sni" style="line-height:17px">The rapid advancement of robotics and artificial intelligence has transformed the <br>
nature of modern military operations. Among these innovations, autonomous <font color=#DD4B39>robot</font> <br>
swarms represent one of the most promising solutions for enhancing operational …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=hKhvR0Aglc8J&amp;citsig=AKwmTV4AAAAAaxLpX-UZFXVEZhM3DNo1IM8zTZM" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://previous.scientia.report/index.php/archive/article/download/3044/3076&amp;rt=Enhancing+operational+effectiveness+through+command+and+control+integration+of+autonomous+robot+swarms&amp;scisig=ABGrvjLroaUQq7m5upP8H2NOAon1" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://previous.scientia.report/index.php/archive/article/download/3044/3076&amp;rt=Enhancing+operational+effectiveness+through+command+and+control+integration+of+autonomous+robot+swarms&amp;scisig=ABGrvjLroaUQq7m5upP8H2NOAon1" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://previous.scientia.report/index.php/archive/article/download/3044/3076&amp;rt=Enhancing+operational+effectiveness+through+command+and+control+integration+of+autonomous+robot+swarms&amp;scisig=ABGrvjLroaUQq7m5upP8H2NOAon1" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[PDF]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://arxiv.org/pdf/2512.01105&amp;hl=zh-CN&amp;sa=X&amp;d=9345656425088029461&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjJ0sJ77yngn2RlZoaHcltK6&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=2&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Supporting productivity skill development in college students through social <font color=#DD4B39>robot </font>coaching: A proof-of-concept</a></h3><div style="color:#006621;line-height:18px">H Lalwani, H Salam - arXiv preprint arXiv:2512.01105, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… a <font color=#DD4B39>robot</font> that delivers positive psychology exercises, while [21] introduced a <font color=#DD4B39>robotic</font> <br>
system … For example, Haru [24] was used for behavior change coaching, and <br>
another <font color=#DD4B39>robotic</font> coach … to productivity coaching using a socially assistive <font color=#DD4B39>robot</font> …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=FRM40gBxsoEJ&amp;citsig=AKwmTV4AAAAAaxLpX7PTim2zchG7gdre3_Y1utk" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://arxiv.org/pdf/2512.01105&amp;rt=Supporting+productivity+skill+development+in+college+students+through+social+robot+coaching:+A+proof-of-concept&amp;scisig=ABGrvjKiQYI69Xt53yykbE7uSpAi" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://arxiv.org/pdf/2512.01105&amp;rt=Supporting+productivity+skill+development+in+college+students+through+social+robot+coaching:+A+proof-of-concept&amp;scisig=ABGrvjKiQYI69Xt53yykbE7uSpAi" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://arxiv.org/pdf/2512.01105&amp;rt=Supporting+productivity+skill+development+in+college+students+through+social+robot+coaching:+A+proof-of-concept&amp;scisig=ABGrvjKiQYI69Xt53yykbE7uSpAi" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[PDF]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://arxiv.org/pdf/2512.00027&amp;hl=zh-CN&amp;sa=X&amp;d=13390999785715310038&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjJ7QXxRnlqjP13QFQsnenOy&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=3&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">A Survey on Improving Human <font color=#DD4B39>Robot </font>Collaboration through Vision-and-Language Navigation</a></h3><div style="color:#006621;line-height:18px">N Yakolli, A Gautam, A Das, Y Qi, VS Shekhawat - arXiv preprint arXiv:2512.00027, 2025</div><div class="gse_alrt_sni" style="line-height:17px">Vision-and-Language Navigation (VLN) is a multi-modal, cooperative task requiring <br>
agents to interpret human instructions, navigate 3D environments, and communicate <br>
effectively under ambiguity. This paper presents a comprehensive review of recent …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=1p3kRltj1rkJ&amp;citsig=AKwmTV4AAAAAaxLpX6yrTlOCQ0mgVaBM0cJXw_g" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://arxiv.org/pdf/2512.00027&amp;rt=A+Survey+on+Improving+Human+Robot+Collaboration+through+Vision-and-Language+Navigation&amp;scisig=ABGrvjLZ1XI6ok4bt1UiVvF8lXC3" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://arxiv.org/pdf/2512.00027&amp;rt=A+Survey+on+Improving+Human+Robot+Collaboration+through+Vision-and-Language+Navigation&amp;scisig=ABGrvjLZ1XI6ok4bt1UiVvF8lXC3" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://arxiv.org/pdf/2512.00027&amp;rt=A+Survey+on+Improving+Human+Robot+Collaboration+through+Vision-and-Language+Navigation&amp;scisig=ABGrvjLZ1XI6ok4bt1UiVvF8lXC3" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[HTML]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://www.mdpi.com/2218-6581/14/12/181&amp;hl=zh-CN&amp;sa=X&amp;d=3132921453952967439&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjJIe5_xBqbdXMbZdk3Mf3do&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=4&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Effectiveness of Unsupervised Training for Applications in Deep Neural Network <font color=#DD4B39>Robot </font>Navigation</a></h3><div style="color:#006621;line-height:18px">Q Wu, J Hedley - Robotics, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… -drive <font color=#DD4B39>robot</font> whose motion is constrained to be either straight or a fixed-radius turn <br>
to either the left or right. This study assumes the <font color=#DD4B39>robot</font> is in a … We also assume <br>
there is a <font color=#DD4B39>robot</font> positional system that can allow the <font color=#DD4B39>robot</font> to determine the required …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=DyMRpHZfeisJ&amp;citsig=AKwmTV4AAAAAaxLpX-lHJqCo0RGqyv__kjKnbOA" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://www.mdpi.com/2218-6581/14/12/181&amp;rt=Effectiveness+of+Unsupervised+Training+for+Applications+in+Deep+Neural+Network+Robot+Navigation&amp;scisig=ABGrvjLEqdc_K3qtos1ihlweuwJr" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://www.mdpi.com/2218-6581/14/12/181&amp;rt=Effectiveness+of+Unsupervised+Training+for+Applications+in+Deep+Neural+Network+Robot+Navigation&amp;scisig=ABGrvjLEqdc_K3qtos1ihlweuwJr" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://www.mdpi.com/2218-6581/14/12/181&amp;rt=Effectiveness+of+Unsupervised+Training+for+Applications+in+Deep+Neural+Network+Robot+Navigation&amp;scisig=ABGrvjLEqdc_K3qtos1ihlweuwJr" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[HTML]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://www.nature.com/articles/s41746-025-02117-9&amp;hl=zh-CN&amp;sa=X&amp;d=7575422873673965085&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjKDHJwYVlYtCNaAC2cK7gZ6&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=5&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">A randomized pilot study evaluating socially assistive <font color=#DD4B39>robot </font>effects on patient engagement and care quality</a></h3><div style="color:#006621;line-height:18px">I Mlakar, U Smrke, V Šafran, IR Roj, B Ilijevec, S Horvat… - npj Digital Medicine, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… Socially assistive <font color=#DD4B39>robots</font> (SARs) have emerged as a promising technology that <br>
could, potentially, address these challenges. These <font color=#DD4B39>robots</font> are … The acceptability <br>
study informed our intervention design and outcome selection, particularly the …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=HZ60oPdOIWkJ&amp;citsig=AKwmTV4AAAAAaxLpX4T-MjMfZ7gr8tGxvqFNVDw" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://www.nature.com/articles/s41746-025-02117-9&amp;rt=A+randomized+pilot+study+evaluating+socially+assistive+robot+effects+on+patient+engagement+and+care+quality&amp;scisig=ABGrvjIecF4ast6QsXo1uErGCY_n" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://www.nature.com/articles/s41746-025-02117-9&amp;rt=A+randomized+pilot+study+evaluating+socially+assistive+robot+effects+on+patient+engagement+and+care+quality&amp;scisig=ABGrvjIecF4ast6QsXo1uErGCY_n" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://www.nature.com/articles/s41746-025-02117-9&amp;rt=A+randomized+pilot+study+evaluating+socially+assistive+robot+effects+on+patient+engagement+and+care+quality&amp;scisig=ABGrvjIecF4ast6QsXo1uErGCY_n" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[HTML]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://www.nature.com/articles/s44182-025-00059-8&amp;hl=zh-CN&amp;sa=X&amp;d=17871133910936661498&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjI1zkq9nExEcDVPMWwaMDuf&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=6&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Fiber-type artificial muscles for <font color=#DD4B39>robotic </font>actuation</a></h3><div style="color:#006621;line-height:18px">JH Moon, JS Hyeon, SH Kim, H Kim, SH Ko, SJ Kim - npj Robotics, 2025</div><div class="gse_alrt_sni" style="line-height:17px">Fiber-type artificial muscles are emerging as innovative components in robotics due <br>
to their lightweight, flexible, and highly adaptable properties that emulate biological <br>
muscle functions. This paper presents a comprehensive overview of recent …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=-i3RTpsFA_gJ&amp;citsig=AKwmTV4AAAAAaxLpXyTCQCEXZVkn63oZA8WDsZg" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://www.nature.com/articles/s44182-025-00059-8&amp;rt=Fiber-type+artificial+muscles+for+robotic+actuation&amp;scisig=ABGrvjLqP1Th7OC2GWHfxuWTpk5g" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://www.nature.com/articles/s44182-025-00059-8&amp;rt=Fiber-type+artificial+muscles+for+robotic+actuation&amp;scisig=ABGrvjLqP1Th7OC2GWHfxuWTpk5g" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://www.nature.com/articles/s44182-025-00059-8&amp;rt=Fiber-type+artificial+muscles+for+robotic+actuation&amp;scisig=ABGrvjLqP1Th7OC2GWHfxuWTpk5g" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[PDF]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://arxiv.org/pdf/2512.01773&amp;hl=zh-CN&amp;sa=X&amp;d=3031651768820343821&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjJFBuZZQW8Fhaj0mi8W8o9d&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=7&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">IGen: Scalable Data Generation for <font color=#DD4B39>Robot </font>Learning from Open-World Images</a></h3><div style="color:#006621;line-height:18px">C Gu, H Kang, J Lin, J Wang, D Wu, S Xie, F Huang… - arXiv preprint arXiv …, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… with <font color=#DD4B39>robotic</font> manipulation tasks, offering a promising avenue for low-cost, large-scale <br>
<font color=#DD4B39>robot</font> … of associated <font color=#DD4B39>robot</font> actions hinders the practical use of open-world images <br>
for <font color=#DD4B39>robot</font> learning, … <font color=#DD4B39>robot</font> data, offering a promising data-driven solution for the …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=DaQ4qziXEioJ&amp;citsig=AKwmTV4AAAAAaxLpXw68GSr47BLn57DERN64WLw" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://arxiv.org/pdf/2512.01773&amp;rt=IGen:+Scalable+Data+Generation+for+Robot+Learning+from+Open-World+Images&amp;scisig=ABGrvjJpU5tNepSsa6j3ArX5nf8R" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://arxiv.org/pdf/2512.01773&amp;rt=IGen:+Scalable+Data+Generation+for+Robot+Learning+from+Open-World+Images&amp;scisig=ABGrvjJpU5tNepSsa6j3ArX5nf8R" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://arxiv.org/pdf/2512.01773&amp;rt=IGen:+Scalable+Data+Generation+for+Robot+Learning+from+Open-World+Images&amp;scisig=ABGrvjJpU5tNepSsa6j3ArX5nf8R" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[HTML]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://www.nature.com/articles/s44182-025-00062-z&amp;hl=zh-CN&amp;sa=X&amp;d=17011078375744872627&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjLet6s4-2Ip6Tm4n5yiO3Lh&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=8&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Multimodal magnetic miniature <font color=#DD4B39>robot </font>for adaptive navigation in amphibious environments</a></h3><div style="color:#006621;line-height:18px">A Zhu, J Zhao, L Yang - npj Robotics, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… <font color=#DD4B39>robots</font> hold great potential for minimally invasive biomedical applications due to <br>
their small size and biocompatibility. However, single-modal <font color=#DD4B39>robots</font> face challenges <br>
in complex environments, while existing multimodal <font color=#DD4B39>robots</font> … novel Multimodal …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=syCaeKd9E-wJ&amp;citsig=AKwmTV4AAAAAaxLpX3p0CWC9WosOzFTp-5f5Kjw" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://www.nature.com/articles/s44182-025-00062-z&amp;rt=Multimodal+magnetic+miniature+robot+for+adaptive+navigation+in+amphibious+environments&amp;scisig=ABGrvjJHf6H3jkCtl16Stfo1-wTw" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://www.nature.com/articles/s44182-025-00062-z&amp;rt=Multimodal+magnetic+miniature+robot+for+adaptive+navigation+in+amphibious+environments&amp;scisig=ABGrvjJHf6H3jkCtl16Stfo1-wTw" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://www.nature.com/articles/s44182-025-00062-z&amp;rt=Multimodal+magnetic+miniature+robot+for+adaptive+navigation+in+amphibious+environments&amp;scisig=ABGrvjJHf6H3jkCtl16Stfo1-wTw" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;margin:0;font-size:17px;line-height:20px;"><span style="font-size:13px;font-weight:normal;color:#1a0dab;vertical-align:2px">[PDF]</span> <a href="https://scholar.google.com.hk/scholar_url?url=https://arxiv.org/pdf/2512.00074&amp;hl=zh-CN&amp;sa=X&amp;d=16384651802348093456&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjL8f02NytZc9mJ4SZXa-Fsq&amp;oi=scholaralrt&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;pos=9&amp;folt=kw-top" class="gse_alrt_title" style="font-size:17px;color:#1a0dab;line-height:22px">Bootstrap Dynamic-Aware 3D Visual Representation for Scalable <font color=#DD4B39>Robot </font>Learning</a></h3><div style="color:#006621;line-height:18px">Q Liang, B Cai, M Lai, S Zhuang, T Lin, Y Qin, Y Ye… - arXiv preprint arXiv …, 2025</div><div class="gse_alrt_sni" style="line-height:17px">… <font color=#DD4B39>Robotic</font> manipulation unfolds as state–action–state trajectories rich in supervisory <br>
signal.Yet … Our core contributions are: (1) We propose a 3D visual pretraining <br>
framework for <font color=#DD4B39>robotic</font> … (3) Extensive simulation and real-<font color=#DD4B39>robot</font> experiments show …</div><div style="width:auto"><table cellpadding="0" cellspacing="0" border="0"><tbody><tr><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;update_op=email_library_add&amp;info=EABsLwH6YeMJ&amp;citsig=AKwmTV4AAAAAaxLpX4hY3rbUrzY06rYtzQxpkWo" style="text-decoration:none;display:inline-block;padding:4px 8px 4px 0;mso-padding-alt:0;"><img alt="保存" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/save-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=tw&amp;url=https://arxiv.org/pdf/2512.00074&amp;rt=Bootstrap+Dynamic-Aware+3D+Visual+Representation+for+Scalable+Robot+Learning&amp;scisig=ABGrvjLhQV1LJefWD8_0FQYDPL8i" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Twitter" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/tw-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=in&amp;url=https://arxiv.org/pdf/2512.00074&amp;rt=Bootstrap+Dynamic-Aware+3D+Visual+Representation+for+Scalable+Robot+Learning&amp;scisig=ABGrvjLhQV1LJefWD8_0FQYDPL8i" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="LinkedIn" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/in-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td><td style="padding-right:4px;mso-padding-alt:4px 16px 0 0;"><a href="https://scholar.google.com/scholar_share?hl=zh-CN&amp;oi=scholaralrt&amp;ss=fb&amp;url=https://arxiv.org/pdf/2512.00074&amp;rt=Bootstrap+Dynamic-Aware+3D+Visual+Representation+for+Scalable+Robot+Learning&amp;scisig=ABGrvjLhQV1LJefWD8_0FQYDPL8i" style="text-decoration:none;display:inline-block;padding:4px 8px;mso-padding-alt:0;"><img alt="Facebook" src="https://scholar.google.com.hk/intl/zh-CN/scholar/images/1x/fb-32.png" border="0" height="16" width="16" style="vertical-align:top"></a></td></tr></tbody></table></div><br><h3 style="font-weight:normal;font-size:18px;line-height:20px;"></h3><div style="line-height:16px;mso-line-height-rule:exactly;border-top:1px solid #bdbdbd">&nbsp;</div><p style="margin:8px 0 16px 0;color:#666">Google 学术搜索发送此邮件，是因为您关注了 <a href="https://scholar.google.com.hk/scholar?q=robot&amp;as_sdt=0,5&amp;scisbd=1&amp;hl=zh-CN" style="color:#1a0dab;">[robot]</a> 的新搜索结果。<img src="https://scholar.google.com.hk/scholar_url?url=https://scholar.google.com.hk/scholar/images/cleardot.gif&amp;hl=zh-CN&amp;sa=X&amp;ei=3rUxadjnO_GQ6rQPuai-sAc&amp;scisig=ABGrvjLwbFM11ufNKqs6p2wOi9ZN&amp;hist=gAQuJI0AAAAJ:7288416964345440708:ABGrvjKyK9lX6FFdTq19sSo15kKZ&amp;html=&amp;folt=kw-top&amp;trs=0,1,2,3,4,5,6,7,8,9" height=1 width=1 alt=""></p><div style="margin-bottom:8px;"><div><!--[if gte mso 9]><table border="0" cellspacing="0" cellpadding="0"><tr><td style="mso-line-height-rule:exactly;line-height:27px;border-top:1px solid #fff;border-bottom:1px solid #fff;mso-text-raise:-1px;"><![endif]--><a href="https://scholar.google.com.hk/scholar_alerts?view_op=list_alerts&amp;email_for_op=ligen4073187%40gmail.com&amp;alert_id=xKm9Bp2oJWUJ&amp;hl=zh-CN" style="display:inline-block;text-decoration:none;font-family:arial,sans-serif;font-size:13px;font-size:13px;font-size:15px;line-height:21px;padding:3px 0;color:#1a0dab;border-top:1px solid transparent;border-bottom:1px solid transparent;border-radius:3px;mso-padding-alt:0;mso-border-alt:none;"><span style="mso-text-raise:5px">列出快讯</span></a><!--[if gte mso 9]></td></tr></table><![endif]--></div><div><!--[if gte mso 9]><table border="0" cellspacing="0" cellpadding="0"><tr><td style="mso-line-height-rule:exactly;line-height:27px;border-top:1px solid #fff;border-bottom:1px solid #fff;mso-text-raise:-1px;"><![endif]--><a href="https://scholar.google.com.hk/scholar_alerts?view_op=cancel_alert_options&amp;email_for_op=ligen4073187%40gmail.com&amp;alert_id=xKm9Bp2oJWUJ&amp;hl=zh-CN&amp;citsig=AKwmTV4AAAAAaUQq3-yphY3M-L5ieKj54NqlOXk" style="display:inline-block;text-decoration:none;font-family:arial,sans-serif;font-size:13px;font-size:13px;font-size:15px;line-height:21px;padding:3px 0;color:#1a0dab;border-top:1px solid transparent;border-bottom:1px solid transparent;border-radius:3px;mso-padding-alt:0;mso-border-alt:none;"><span style="mso-text-raise:5px">取消快讯</span></a><!--[if gte mso 9]></td></tr></table><![endif]--></div></div></div><!--[if gte mso 9]></td></tr></table><![endif]--></body></html>
